{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d2bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:4996\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/css/bootstrap.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/css/responsive.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/css/custom.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/js/modernizr.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/profile.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/sentiment.PNG HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/js/all.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/js/jquery.mobile.customized.min.js HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/css/animate.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/css/camera.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/css/flaticon.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/css/prettyPhoto.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/css/owl.carousel.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/css/font-awesome.min.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/css/timeline.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/js/jquery.easing.1.3.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/js/parallaxie.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/js/headline.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/js/jqBootstrapValidation.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/js/contact_me.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/js/custom.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/js/jquery.vide.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/rainfall.svg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/lidar.svg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/salary.svg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/dash.svg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/lrasm.svg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/gmail.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/LinkedIn_icon.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/github-512.webp HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/header.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/images/country-quilt-dark.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/TD_Canada_Trust_logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/fonts/fontawesome-webfont.woff2?v=4.6.3 HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/royaldist.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET /static/uploads/tmmc.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:32] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Jun/2025 10:59:38] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm not sure what you mean, please ask another question.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "from backend import response\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/chat', methods=['GET', 'POST'])\n",
    "def chat():\n",
    "    message = request.form['msg']\n",
    "    return response(message)\n",
    "\n",
    "app.run(port=4996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b08351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    bedrock = boto3.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name='us-east-2',\n",
    "    )\n",
    "\n",
    "    formatted_prompt = event['query']\n",
    "\n",
    "    model_id = \"us.meta.llama3-2-1b-instruct-v1:0\"\n",
    "\n",
    "    native_request = {\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"max_gen_len\": 256,\n",
    "        \"temperature\": 0.5,\n",
    "    }\n",
    "\n",
    "    # Convert the native request to JSON.\n",
    "    request = json.dumps(native_request)\n",
    "\n",
    "    try:\n",
    "        # Invoke the model with the request.\n",
    "        response = bedrock.invoke_model(modelId=model_id, body=request)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bcd2662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" As a seasoned data scientist, I've had the privilege of working with various datasets, but I must say that one of the most fascinating projects I've undertaken was analyzing a dataset on the relationship between income and education levels in a small town. The dataset was a mix of quantitative and qualitative variables, including income, education level, occupation, and family size. By using a combination of regression analysis and clustering techniques, I was able to identify distinct groups within the population, including high-income earners with high education levels and low-income earners with low education levels. The results suggested that education level had a significant impact on income, with higher education leading to higher income, while family size and occupation also played a role.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = boto3.client(service_name = 'lambda', \n",
    "                      region_name=\"us-east-2\")\n",
    "\n",
    "payloaddict = {\"query\" : \"hello\", \"context\" : \"none\"}\n",
    "\n",
    "payload = json.dumps(payloaddict)\n",
    "out = client.invoke(\n",
    "        FunctionName=\"llamaInferenceSyang\",\n",
    "        InvocationType='RequestResponse',\n",
    "        Payload = payload\n",
    "    )\n",
    "\n",
    "json.loads(out[\"Payload\"].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb67459",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('ayangvectorstore1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff08b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\" As a data scientist, I\\'ve worked with various datasets and algorithms to analyze and visualize complex data. One of the most common challenges in data analysis is dealing with missing values. In many cases, missing values can significantly impact the accuracy and reliability of the analysis. To address this, I often employ techniques such as imputation, which involves replacing missing values with appropriate estimates using various methods, such as mean, median, or regression models. Additionally, I also consider the context and the specific requirements of the analysis to determine the most suitable method for each dataset.\"'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01c30781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"generation\":\" I\\'m here to help with any questions or topics you have in mind. What would you like to talk about?\",\"prompt_token_count\":36,\"generation_token_count\":24,\"stop_reason\":\"stop\"}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtext = response[\"body\"].read()\n",
    "rtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb7c90b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000@localhost:8080 \"/usr/local/bin\" 0 0 root root 4096 Jan 1 14:30:01 localhost systemd-journald.service 0 0 root root 4096 Jan 1 14:30:01 localhost systemd-journald.service 0 0 root root 4096 Jan 1 14:30:01 localhost systemd-journald.service 0 0 root root 4096 Jan 1 14:30:01 localhost systemd-journald.service 0 0 root root 4096 Jan 1 14:30:01 localhost systemd-journald.service 0 0 root root 4096 Jan 1 14:30:01 localhost systemd-journald.service 0 0 root root 4096 Jan 1 14:30:01 localhost systemd-journald.service 0 0 root root 4096 Jan 1 14:30:01 localhost systemd-journald.service 0 0 root root 4096 Jan 1 14:30:01 localhost systemd-journald.service 0 0 root root 4096 Jan 1 14:30:01 localhost systemd-journald.service 0 '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(rtext)[\"generation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21aaf3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><strong>asd</strong></p>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from markdown import markdown\n",
    "markdown(\"**asd**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06107f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.vector_stores.types import BasePydanticVectorStore\n",
    "from llama_index.core.vector_stores import (\n",
    "    VectorStoreQuery,\n",
    "    VectorStoreQueryResult,\n",
    ")\n",
    "from typing import List, Any, Optional, Dict\n",
    "from llama_index.core.schema import TextNode, BaseNode\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f17b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601043d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"C:/Users/andy8/Projects/Resume/ResumeIn/ChatGPT Template Resume.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "for page in loader.load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7be75241",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(pages)\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "vectorstore.save_local(\"vectortore\")\n",
    "\n",
    "# vector_store = InMemoryVectorStore.from_documents(pages, OpenAIEmbeddings())\n",
    "# docs = vector_store.similarity_search(\"What is LayoutParser?\", k=2)\n",
    "# for doc in docs:\n",
    "#     print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[:300]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d552e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = FAISS.load_local(\"vectortore\", OpenAIEmbeddings(), allow_dangerous_deserialization = True)\n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf865b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10ec72a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ANDY YANG \\n+1-647-461-6466 • syyyang003@gmail.com • Toronto, ON / Vancouver, BC • LinkedIn • Portfolio • GitHub \\nPROFESSIONAL SUMMARY \\nAnalytics Engineer with 5 years' experience automating data workflows, building Python-based tools, and deploying scalable \\nsolutions across fintech and tech. Skilled in developing internal applications, APIs, and cloud pipelines (AWS, Azure) to \\nstreamline analytics and improve stakeholder access. Passionate about transforming manual processes into reusable \\nsystems that enhance speed, accuracy, and cross-functional decision-making. \\nCORE COMPETENCIES \\nCoding Languages: Python (Plotly, Pandas, PyTorch), R (Rshiny), Jupyter Notebooks, PySpark, SAS, SQL \\nMachine Learning: Hypothesis Testing, A/B testing, Deep Learning, LLMs, A/B Testing, Predictive Modeling \\nData Engineering: MS Azure, Hadoop, Tableau, Power BI, AWS, Spark, Jira, Confluence, Docker\\n\\nEDUCATION  \\nMaster’s of Data Science Sep 2021 – Jul 2022 \\nUniversity of British Columbia, Vancouver, BC \\nBachelor’s of Applied Science in Chemical Engineering Sep 2016 – Apr 2021 \\nUniversity of Waterloo, Waterloo, ON \\nINTERESTS \\nSkiing and Snowboarding (Former Instructor), Coffee Enthusiast, Travel, Guitar, Cooking, Console Gaming\\n\\n● Acted as a bridge between shop floor managers and technology teams to implement and schedule server \\ninstallations. \\nJohnson and Johnson - Markham, ON \\nSupply Chain Coordinator Co-op  May 2019 – Aug 2019 \\n● Introduced novel data analysis tools using VBA and PowerQuery in Excel to provide automated report generation, in -\\ndepth analytics, and a custom dashboard for supply chain metrics , reducing weekly report generation time from \\nover 10 hours to under 2 hours. \\nPROJECTS \\nLiDAR Object Detection and Classification for Cities PyTorch, AWS (S3, SageMaker), Deep Learning \\nReliance Foundry Co. Ltd., University of British Columbia \\n● Designed deep learning pipelines using PyTorch and AWS to classify 3D LiDAR data for smart city applications, \\nachieving 93%+ model precision — demonstrating ability to deploy machine learning in production environments . \\nEDUCATION  \\nMaster’s of Data Science Sep 2021 – Jul 2022 \\nUniversity of British Columbia, Vancouver, BC\\n\\nMachine Learning: Hypothesis Testing, A/B testing, Deep Learning, LLMs, A/B Testing, Predictive Modeling \\nData Engineering: MS Azure, Hadoop, Tableau, Power BI, AWS, Spark, Jira, Confluence, Docker \\nSoft Skills: Communication, Stakeholder Management, Critical Thinking, Customer Segmentation, Presentation \\nWORK EXPERIENCE \\nTD Bank Group - Toronto, ON \\nSenior Model Validation Analyst – Data Science Apr 2023 - Present \\n● Designed and implemented scalable Python- and SQL-based pipelines that automated data flows into executive -\\nlevel dashboards (Tableau), supporting credit risk strategy across multi -billion-dollar financial portfolios. \\n● Built PySpark-based automation pipelines on Azure Databricks to validate model performance metrics (AUROC, \\ncalibration), reducing runtime by 50% and enhancing analytics workflow efficiency and reliability . \\n● Fine-tuned and deployed an internal LLM-powered RAG (Retrieval-Augmented Generation) pipeline with LangChain\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.invoke(\"where did Andy go to school?\")\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "format_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ac639dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andy Yang's work experience can be summarized as follows:\n",
      "\n",
      "**Senior Model Validation Analyst - Data Science, TD Bank Group (Apr 2023 - Present)**\n",
      "\n",
      "* Designed and implemented scalable Python- and SQL-based pipelines to automate data flows into executive-level dashboards, supporting credit risk strategy across multi-billion-dollar financial portfolios.\n",
      "* Built PySpark-based automation pipelines on Azure Databricks to validate model performance metrics (AUROC, calibration), reducing runtime by 50% and enhancing analytics workflow efficiency and reliability.\n",
      "* Fine-tuned and deployed an internal LLM-powered RAG (Retrieval-Augmented Generation) pipeline with LangChain.\n",
      "\n",
      "**Senior Model Validation Analyst - Data Science, TD Bank Group (Apr 2023 - Present)**\n",
      "\n",
      "* Designed and implemented scalable Python- and SQL-based pipelines to automate data flows into executive-level dashboards, supporting credit risk strategy across multi-billion-dollar financial portfolios.\n",
      "* Built PySpark-based automation pipelines on Azure Databricks to validate model performance metrics (AUROC, calibration), reducing runtime by 50% and enhancing analytics workflow efficiency and reliability.\n",
      "* Fine-tuned and deployed an internal LLM-powered RAG (Retrieval-Augmented Generation) pipeline with LangChain.\n",
      "\n",
      "**Supply Chain Coordinator Co-op, Johnson and Johnson (May 2019 - Aug 2019)**\n",
      "\n",
      "* Introduced novel data analysis tools using VBA and PowerQuery in Excel to provide automated report generation, in-depth analytics, and a custom dashboard for supply chain metrics.\n",
      "* Reduced weekly report generation time from over 10 hours to under 2 hours.\n",
      "\n",
      "**Project Experience:**\n",
      "\n",
      "* **LiDAR Object Detection and Classification for Cities PyTorch, AWS (S3, SageMaker), Deep Learning**: Designed deep learning pipelines using PyTorch and AWS to classify 3D LiDAR data for smart city applications, achieving 93%+ model precision.\n",
      "* **Other Projects**: Various projects related to machine learning, data engineering, and data science, including a project on LLM-powered RAG (Retrieval-Augmented Generation) pipeline with LangChain.\n",
      "\n",
      "Andy Yang's experience spans over 5 years, with a strong background in data science, machine learning, and cloud computing. He has worked on various projects, including credit risk strategy, supply chain management, and smart city applications. His expertise in Python, PySpark, and deep learning frameworks (PyTorch, SageMaker) is evident throughout his work experience.\n"
     ]
    }
   ],
   "source": [
    "# Create a Bedrock Runtime client in the AWS Region of your choice.\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-2\")\n",
    "\n",
    "# Set the model ID, e.g., Llama 3 70b Instruct.\n",
    "model_id = \"us.meta.llama3-2-1b-instruct-v1:0\"\n",
    "\n",
    "# Define the prompt for the model.\n",
    "prompt = \"Tell me about Andy's work experience.\"\n",
    "\n",
    "context = format_docs(retriever.invoke(prompt))\n",
    "\n",
    "# Embed the prompt in Llama 3's instruction format.\n",
    "formatted_prompt = f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "Answer the statement while conidering the following context: {context}\n",
    "{prompt}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "# Format the request payload using the model's native structure.\n",
    "native_request = {\n",
    "    \"prompt\": formatted_prompt,\n",
    "    \"max_gen_len\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "}\n",
    "\n",
    "# Convert the native request to JSON.\n",
    "request = json.dumps(native_request)\n",
    "\n",
    "try:\n",
    "    # Invoke the model with the request.\n",
    "    response = client.invoke_model(modelId=model_id, body=request)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Decode the response body.\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Extract and print the response text.\n",
    "response_text = model_response[\"generation\"]\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dcbadee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Andy Yang's work experience can be summarized as follows:\\n\\n**Senior Model Validation Analyst - Data Science, TD Bank Group (Apr 2023 - Present)**\\n\\n* Designed and implemented scalable Python- and SQL-based pipelines to automate data flows into executive-level dashboards, supporting credit risk strategy across multi-billion-dollar financial portfolios.\\n* Built PySpark-based automation pipelines on Azure Databricks to validate model performance metrics (AUROC, calibration), reducing runtime by 50% and enhancing analytics workflow efficiency and reliability.\\n* Fine-tuned and deployed an internal LLM-powered RAG (Retrieval-Augmented Generation) pipeline with LangChain.\\n\\n**Senior Model Validation Analyst - Data Science, TD Bank Group (Apr 2023 - Present)**\\n\\n* Designed and implemented scalable Python- and SQL-based pipelines to automate data flows into executive-level dashboards, supporting credit risk strategy across multi-billion-dollar financial portfolios.\\n* Built PySpark-based automation pipelines on Azure Databricks to validate model performance metrics (AUROC, calibration), reducing runtime by 50% and enhancing analytics workflow efficiency and reliability.\\n* Fine-tuned and deployed an internal LLM-powered RAG (Retrieval-Augmented Generation) pipeline with LangChain.\\n\\n**Supply Chain Coordinator Co-op, Johnson and Johnson (May 2019 - Aug 2019)**\\n\\n* Introduced novel data analysis tools using VBA and PowerQuery in Excel to provide automated report generation, in-depth analytics, and a custom dashboard for supply chain metrics.\\n* Reduced weekly report generation time from over 10 hours to under 2 hours.\\n\\n**Project Experience:**\\n\\n* **LiDAR Object Detection and Classification for Cities PyTorch, AWS (S3, SageMaker), Deep Learning**: Designed deep learning pipelines using PyTorch and AWS to classify 3D LiDAR data for smart city applications, achieving 93%+ model precision.\\n* **Other Projects**: Various projects related to machine learning, data engineering, and data science, including a project on LLM-powered RAG (Retrieval-Augmented Generation) pipeline with LangChain.\\n\\nAndy Yang's experience spans over 5 years, with a strong background in data science, machine learning, and cloud computing. He has worked on various projects, including credit risk strategy, supply chain management, and smart city applications. His expertise in Python, PySpark, and deep learning frameworks (PyTorch, SageMaker) is evident throughout his work experience.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9af2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
